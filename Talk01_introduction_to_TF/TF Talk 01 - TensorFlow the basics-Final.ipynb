{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Crash Course for Developers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is TensorFlow?\n",
    "\n",
    " - A tool for building computational graphs\n",
    " - It allows for the graph to be distributed over many many CPUs/GPUs\n",
    " - Up till now TensorFlow has been a low level Lib \n",
    " - This is changing going forward \n",
    " - TensorFlow has fast become the standard library for Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow the big concepts\n",
    "\n",
    " in TF is a computational graph with operations on it\n",
    " \n",
    " \n",
    " \n",
    " ### 1. Graph\n",
    " \n",
    "         - Everything must be built on the graph before you excute. \n",
    "         - We can do this in a variety of languages\n",
    "         - The graph is run it will be in C++\n",
    "         - We use Python to define the graph but then it gets turned into c++/CUDA etc for running\n",
    "         - With new XLA TF will edit/create an optimized graph\n",
    "         \n",
    " ### 2. Operations \n",
    " \n",
    "         - Operations are performed on a graph\n",
    "         - Standard math operations\n",
    "         - Allow a high level of granularity in your model\n",
    "\n",
    " ### 3. Sessions \n",
    " \n",
    "         - Sessions execute the graph\n",
    "         - Nothing is run till you init and run a session\n",
    "         \n",
    "         \n",
    " ### 4. TensorBoard\n",
    " \n",
    "         - Gives us a visual representation of our model \n",
    "         - Gives us stats about our training variables like loss accuracy etc\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing TensorFlow and checking the version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The graph\n",
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reseting Tensorboard\n",
    "sess = tf.Session()\n",
    "#!rm -rf log_simple_graph\n",
    "#!rm -rf matrix_graph\n",
    "#!rm -rf log_simple_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating some example operations\n",
    "\n",
    "Simple Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./diagram12.gif\" style=\"width:700px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample input to make graph above\n",
    "input_a = tf.constant(4., dtype =tf.float32 ,name='a')\n",
    "input_b = tf.constant(3., dtype =tf.float32, name='b')\n",
    "\n",
    "#simple_addition operator\n",
    "c = tf.add(input_a,input_b,name='a_plus_b')\n",
    "\n",
    "#simple_mulitplication\n",
    "d = tf.multiply(input_a,input_b,name='a_mul_b')\n",
    "\n",
    "#\n",
    "e = tf.multiply(c,d,name='c_mul_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a_plus_b:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# without a running a session we don't get any values\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look inside these operation objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a   Const\n",
      "b   Const\n",
      "a_plus_b   Add\n",
      "a_mul_b   Mul\n",
      "c_mul_d   Mul\n"
     ]
    }
   ],
   "source": [
    "#Examining our operations\n",
    "operations = graph.get_operations()\n",
    "for operation in operations:\n",
    "    print(operation.name,\" \", operation.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"a_mul_b\"\n",
       "op: \"Mul\"\n",
       "input: \"a\"\n",
       "input: \"b\"\n",
       "attr {\n",
       "  key: \"T\"\n",
       "  value {\n",
       "    type: DT_FLOAT\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations[-2].node_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "### Runnning the Graph in a session\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Runnning the Graph in a session\n",
    "summary_writer = tf.summary.FileWriter('log_simple', sess.graph)\n",
    "sess.run(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard b'41' on port 6006\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samwitteveen/anaconda/envs/tf01/bin/tensorboard\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/samwitteveen/anaconda/envs/tf01/lib/python3.5/site-packages/tensorflow/tensorboard/tensorboard.py\", line 151, in main\n",
      "    tb_server.serve_forever()\n",
      "  File \"/Users/samwitteveen/anaconda/envs/tf01/lib/python3.5/socketserver.py\", line 232, in serve_forever\n",
      "    ready = selector.select(poll_interval)\n",
      "  File \"/Users/samwitteveen/anaconda/envs/tf01/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=log_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Tensor\n",
    "\n",
    "\n",
    "<img src=\"./diagram5g.png\" style=\"width:800px;\">\n",
    "\n",
    "multi dimensional array/matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The graph\n",
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "!rm -rf matrix_graph\n",
    "!rm -rf log_simple\n",
    "\n",
    "\n",
    "#tensor_a = tf.random_normal(shape=[3,3], mean=0.0,stddev=1.0, dtype=tf.float32,name='tensor_a')\n",
    "tensor_a = tf.constant([[4,5,6],[1,3,5],[3,1,3]],shape=[3,3], dtype =tf.float32 ,name='tensor_b')\n",
    "tensor_b = tf.constant([[4.,3,5],[12,3,45],[63,41,3]],shape=[3,3], dtype =tf.float32 ,name='tensor_b')\n",
    "\n",
    "tensor_matrix_mul = tf.matmul(tensor_a,tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(3)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting tensor shape  \n",
    "tensor_a.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.  5.  6.]\n",
      " [ 1.  3.  5.]\n",
      " [ 3.  1.  3.]]\n"
     ]
    }
   ],
   "source": [
    "### Runnning the Graph in a session\n",
    "print(sess.run(tensor_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.   3.   5.]\n",
      " [ 12.   3.  45.]\n",
      " [ 63.  41.   3.]]\n"
     ]
    }
   ],
   "source": [
    "#sess = tf.Session()\n",
    "print(sess.run(tensor_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\begin{bmatrix}\n",
    "    4 &  5 &  6 \\\\\n",
    "    1  & 3 &  5 \\\\\n",
    "    3  & 1 &  3 \\\\\n",
    "\\end{bmatrix}\n",
    "•\n",
    "\\begin{bmatrix}\n",
    "    4 &  3 &  5 \\\\\n",
    "    12 &  3 &  45 \\\\\n",
    "    63 &  41 &  3 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    454 &  273 &  263 \\\\\n",
    "    355 &  217 &  155 \\\\\n",
    "    213 & 135 &  69 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 454.  273.  263.]\n",
      " [ 355.  217.  155.]\n",
      " [ 213.  135.   69.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tensor_matrix_mul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard b'41' on port 6006\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samwitteveen/anaconda/envs/tf01/bin/tensorboard\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/samwitteveen/anaconda/envs/tf01/lib/python3.5/site-packages/tensorflow/tensorboard/tensorboard.py\", line 151, in main\n",
      "    tb_server.serve_forever()\n",
      "  File \"/Users/samwitteveen/anaconda/envs/tf01/lib/python3.5/socketserver.py\", line 232, in serve_forever\n",
      "    ready = selector.select(poll_interval)\n",
      "  File \"/Users/samwitteveen/anaconda/envs/tf01/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "### Runnning the Graph on tensor board\n",
    "summary_writer = tf.summary.FileWriter('matrix_graph', sess.graph)\n",
    "!tensorboard --logdir=matrix_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building your first network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Model with Pure TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST from TF Examples\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "# Load data\n",
    "X_train = mnist.train.images\n",
    "Y_train = mnist.train.labels\n",
    "X_test = mnist.test.images\n",
    "Y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Image Tensor X_train\n",
    "\n",
    "<img src=\"./diagram4f.png\" style=\"width:550px;\">\n",
    "<img src=\"./diagram6d.png\" style=\"width:550px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119a89d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ny5TDb5Yph98sUw6/WaYcfrNMOfxmmfp/uSvDKbOg1JQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125abb630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125abb240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Method for displaying the number as a picture\n",
    "\n",
    "def show_digit(index):\n",
    "    label = Y_train[index].argmax(axis=0)\n",
    "    # Reshape 784 array into 28x28 image\n",
    "    image = X_train[index].reshape([28,28])\n",
    "    fig, axes = plt.subplots(1, )\n",
    "    fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "    plt.title('Training data, index: %d,  Label: %d' % (index, label))\n",
    "    plt.imshow(image, cmap='gray_r')\n",
    "    plt.show()\n",
    "    \n",
    "def show_predicted_digit(image, pred, label):\n",
    "    # Reshape 784 array into 28x28 image\n",
    "    image = image.reshape([28,28])\n",
    "    plt.title('Original Image, Pred: %d,  True Label: %d' %(pred, label))\n",
    "    plt.imshow(image, cmap='gray_r')\n",
    "    plt.show()\n",
    "    \n",
    "# Display the first (index 0) training image\n",
    "show_digit(1)\n",
    "show_digit(2)\n",
    "show_digit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batching allows TF to streamline a cimputation for the processors eg. GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a batch of 64 images and their labels\n",
    "batch_X, batch_Y = mnist.train.next_batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 784)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./diagram3c.gif\" style=\"width:750px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up our Network Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters for basic MNIST\n",
    "learning_rate = 0.1 \n",
    "training_epochs = 2\n",
    "batch_size = 100\n",
    "display_step = 1  # for how often to print out our results\n",
    "model_path = \"./talk_save/model1.ckpt\" #\"./talk_save/model.ckpt\"\n",
    "alt_model_path = \"./talk_save/model.ckpt\" #\"./talk_save/model.ckpt\"\n",
    "\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28 flattened to be 784)\n",
    "n_hidden_1 = 384 # 1st layer number of neurons\n",
    "n_hidden_2 = 100 # 2nd layer number of neurons\n",
    "n_classes = 10 # MNIST classes for prediction(digits 0-9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The graph\n",
    "tf.reset_default_graph()\n",
    "#!rm -rf log_simple_graph\n",
    "!rm -rf matrix_graph\n",
    "#!rm -rf log_simple_graph/3\n",
    "\n",
    "\n",
    "# tf Graph input\n",
    "with tf.name_scope('Inputs') as scope:\n",
    "    x = tf.placeholder(\"float\", [None, n_input],name='x_input')\n",
    "    y = tf.placeholder(\"float\", [None, n_classes],name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x):\n",
    "    \n",
    "    with tf.name_scope('hidden_01') as scope:\n",
    "        # Hidden layer 01 with RELU activation\n",
    "        \n",
    "        #weights and bias tensor\n",
    "        h1weight = tf.Variable(tf.truncated_normal([n_input, n_hidden_1],stddev=0.1),name='h1_weights')\n",
    "        h1bias = tf.Variable(tf.truncated_normal([n_hidden_1],stddev=0.1),name='b1_bias')\n",
    "        \n",
    "        #hidden layer 01 Ops\n",
    "        layer_1 = tf.add(tf.matmul(x, h1weight), h1bias,name='Layer1_matmul')  # adding (x•w1) + bias1)\n",
    "        layer_1 = tf.nn.relu(layer_1, name='Layer1_Relu') #activation Relu passes anything above 0 and blocks negative\n",
    "        \n",
    "        #tensorboard histograms for layer 01\n",
    "        tf.summary.histogram('weights_h1',h1weight)\n",
    "        tf.summary.histogram('bias_h1',h1bias)\n",
    "        \n",
    "    with tf.name_scope('hidden_02') as scope:\n",
    "        # Hidden layer 02 with RELU activation\n",
    "        h2weights = tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2],stddev=0.1),name='h2_weights')\n",
    "        h2bias = tf.Variable(tf.truncated_normal([n_hidden_2],stddev=0.1),name='b2_bias')\n",
    "        \n",
    "        layer_2 = tf.add(tf.matmul(layer_1, h2weights), h2bias,name='Layer2_add')\n",
    "        layer_2 = tf.nn.relu(layer_2, name='Layer2_Relu')\n",
    "        #tensorboard histograms\n",
    "        tf.summary.histogram('weights_h2',h2weights)\n",
    "        tf.summary.histogram('bias_h2',h2bias)\n",
    "        \n",
    "    with tf.name_scope('output_layer') as scope:\n",
    "        # Logits layer with linear activation\n",
    "        output_weights = tf.Variable(tf.truncated_normal([n_hidden_2, n_classes],stddev=0.1),name='output_weights')\n",
    "        output_bias = tf.Variable(tf.truncated_normal([n_classes],stddev=0.1),name='out_bias')\n",
    "        \n",
    "        logits_layer = tf.add(tf.matmul(layer_2, output_weights), output_bias,name='logits')\n",
    "\n",
    "    return logits_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels= y, logits=pred ))   #compute the error against the correct results\n",
    "\n",
    "with tf.name_scope('train'):    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss) # optimizer makes changes to the weights and bias to reduce loss\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Saver' op to save and restore all the variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Runnning the Graph on tensor board\n",
    "file_writer = tf.summary.FileWriter('log_simple_graph/9', sess.graph)\n",
    "\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network by running the Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Loss = 1.477629425\n",
      "Epoch: 0002 Loss = 0.731560423\n",
      "Optimization Finished!\n",
      "Model saved to: ./talk_save/model1.ckpt\n",
      "CPU times: user 53.8 s, sys: 2.27 s, total: 56.1 s\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c,summary = sess.run([optimizer, loss,summary_op], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "            #write to file TensorBoard variables\n",
    "            file_writer.add_summary(summary, epoch  + i)\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"Loss =\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    print (\"Optimization Finished!\")\n",
    "    \n",
    "\n",
    "    # Save model weights to disk\n",
    "    save_path = saver.save(sess, model_path)\n",
    "    print (\"Model saved to: %s\" % save_path)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing against our Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored from file: ./talk_save/model1.ckpt\n",
      "Accuracy: 0.741\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Restore model weights from previously saved model\n",
    "    load_path = saver.restore(sess, model_path)\n",
    "    print (\"Model restored from file: %s\" % save_path)\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print (\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard b'41' on port 6006\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/samwitteveen/anaconda/envs/tf01/bin/tensorboard\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/samwitteveen/anaconda/envs/tf01/lib/python3.5/site-packages/tensorflow/tensorboard/tensorboard.py\", line 151, in main\n",
      "    tb_server.serve_forever()\n",
      "  File \"/Users/samwitteveen/anaconda/envs/tf01/lib/python3.5/socketserver.py\", line 232, in serve_forever\n",
      "    ready = selector.select(poll_interval)\n",
      "  File \"/Users/samwitteveen/anaconda/envs/tf01/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=log_simple_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAEICAYAAABf40E1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZolzCJglziFgljiHgFniHAJmifs/ud0l+Y0nDzsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125b6d2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_image_from_test(imageNumber):\n",
    "    imvalue = X_test[imageNumber]\n",
    "    trueValue = np.argmax(Y_test[imageNumber],0)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Restore model weights from previously saved model\n",
    "        load_path = saver.restore(sess, model_path)\n",
    "        # Predict model 1 image batch size = 1\n",
    "        vector = sess.run(pred, feed_dict={x: [imvalue]})\n",
    "        #print(vector[0])\n",
    "        pred_label = sess.run(tf.argmax(vector[0],0))\n",
    "        #show image and result\n",
    "        show_predicted_digit(imvalue, pred_label, trueValue)\n",
    "        \n",
    "predict_image_from_test(34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Board\n",
    "\n",
    "#### clear the graph so you can start from scratch\n",
    "\n",
    "tf.reset_default_graph()  \n",
    "sess = tf.Session()\n",
    "\n",
    "#### create a file writer\n",
    "\n",
    "file_writer = tf.summary.FileWriter('log_simple_graph/2', sess.graph)\n",
    "\n",
    "#### save a summary of a continuous scalar value \n",
    "\n",
    "tf.summary.scalar(\"accuracy\", accuracy)  \n",
    "tf.summary.scalar(\"loss\", loss)  \n",
    "\n",
    "#### save a summary of a continuous value as histogram\n",
    "\n",
    "tf.summary.histogram('weights_h1',h1weight)  \n",
    "tf.summary.histogram('bias_h1',h1bias)  \n",
    "\n",
    "#### merge the summaries to one model\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "#### logging the info when training\n",
    "\n",
    "file_writer.add_summary(summary, epoch  + batch)  \n",
    "summary = sess.run([optimizer, loss,summary_op], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "#### Running the TensorBoard \n",
    "!tensorboard --logdir=log_simple_graph  \n",
    "(!) is for jupyter to access the command line  \n",
    "(log_simple_graph) is the folder with the graph in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Sentiment Analysis Network\n",
    "\n",
    "Using the same model as before lets see how it performs on a totally different type of problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read IMDB movie reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('./imdb_data/reviews.txt', header=None)\n",
    "labels = pd.read_csv('./imdb_data/labels_ohe.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'airport    starts as a brand new luxury    plane is loaded up with valuable paintings  such belonging to rich businessman philip stevens  james stewart  who is flying them  a bunch of vip  s to his estate in preparation of it being opened to the public as a museum  also on board is stevens daughter julie  kathleen quinlan   her son . the luxury jetliner takes off as planned but mid  air the plane is hi  jacked by the co  pilot chambers  robert foxworth   his two accomplice  s banker  monte markham   wilson  michael pataki  who knock the passengers  crew out with sleeping gas  they plan to steal the valuable cargo  land on a disused plane strip on an isolated island but while making his descent chambers almost hits an oil rig in the ocean  loses control of the plane sending it crashing into the sea where it sinks to the bottom right bang in the middle of the bermuda triangle . with air in short supply  water leaking in  having flown over    miles off course the problems mount for the survivor  s as they await help with time fast running out . . .  br    br   also known under the slightly different tile airport     this second sequel to the smash  hit disaster thriller airport       was directed by jerry jameson  while once again like it  s predecessors i can  t say airport    is any sort of forgotten classic it is entertaining although not necessarily for the right reasons . out of the three airport films i have seen so far i actually liked this one the best  just . it has my favourite plot of the three with a nice mid  air hi  jacking  then the crashing  didn  t he see the oil rig    sinking of the     maybe the makers were trying to cross the original airport with another popular disaster flick of the period the poseidon adventure         submerged is where it stays until the end with a stark dilemma facing those trapped inside  either suffocate when the air runs out or drown as the    floods or if any of the doors are opened  it  s a decent idea that could have made for a great little disaster flick but bad unsympathetic character  s  dull dialogue  lethargic set  pieces  a real lack of danger or suspense or tension means this is a missed opportunity . while the rather sluggish plot keeps one entertained for    odd minutes not that much happens after the plane sinks  there  s not as much urgency as i thought there should have been . even when the navy become involved things don  t pick up that much with a few shots of huge ships  helicopters flying about but there  s just something lacking here . george kennedy as the jinxed airline worker joe patroni is back but only gets a couple of scenes  barely even says anything preferring to just look worried in the background .  br    br   the home video  theatrical version of airport    run    minutes while the us tv versions add an extra hour of footage including a new opening credits sequence  many more scenes with george kennedy as patroni  flashbacks to flesh out character  s  longer rescue scenes  the discovery or another couple of dead bodies including the navigator . while i would like to see this extra footage i am not sure i could sit through a near three hour cut of airport    . as expected the film has dated badly with horrible fashions  interior design choices  i will say no more other than the toy plane model effects aren  t great either . along with the other two airport sequels this takes pride of place in the razzie award  s hall of shame although i can think of lots of worse films than this so i reckon that  s a little harsh . the action scenes are a little dull unfortunately  the pace is slow  not much excitement or tension is generated which is a shame as i reckon this could have been a pretty good film if made properly .  br    br   the production values are alright if nothing spectacular . the acting isn  t great  two time oscar winner jack lemmon has said since it was a mistake to star in this  one time oscar winner james stewart looks old  frail  also one time oscar winner lee grant looks drunk while sir christopher lee is given little to do  there are plenty of other familiar faces to look out for too .  br    br   airport    is the most disaster orientated of the three airport films so far  i liked the ideas behind it even if they were a bit silly  the production  bland direction doesn  t help though  a film about a sunken plane just shouldn  t be this boring or lethargic . followed by the concorde . . . airport          .  '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()\n",
    "reviews[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in data set:  74074\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_counts = Counter()\n",
    "for i,row in reviews.iterrows():\n",
    "    total_counts.update(row[0].split(' '))\n",
    "\n",
    "print(\"Total words in data set: \", len(total_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'were', 'me', 'well', 'than', 'much', 'get', 'bad', 'been', 'people']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(total_counts, key=total_counts.get, reverse=True)[:10000]\n",
    "print(vocab[70:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad :  9308\n"
     ]
    }
   ],
   "source": [
    "print(vocab[77], ': ', total_counts[vocab[77]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2idx = {word: i for i, word in enumerate(vocab)} #dictionary comprehension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    word_vector = np.zeros(len(vocab), dtype=np.int_)\n",
    "    for word in text.split(' '):\n",
    "        idx = word2idx.get(word,None)\n",
    "        if idx is None:\n",
    "            continue\n",
    "        else:\n",
    "            word_vector[idx] = 1 # was += 1\n",
    "    return np.array(word_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_vector('There were lots of good movies and stars this year')[:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors = np.zeros((len(reviews), len(vocab)), dtype=np.int_)\n",
    "for ii, (_, text) in enumerate(reviews.iterrows()):\n",
    "    word_vectors[ii] = text_to_vector(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1]\n",
      " [1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1]]\n",
      "                                                   0\n",
      "0  bromwell high is a cartoon comedy . it ran at ...\n",
      "1  story of a man who has unnatural feelings for ...\n",
      "2  homelessness  or houselessness as george carli...\n"
     ]
    }
   ],
   "source": [
    "# Printing out the first 5 word vectors\n",
    "print(word_vectors[:3, :25])\n",
    "print(reviews[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 10000)\n",
      "(22500, 2)\n",
      "(2500, 10000)\n",
      "(2500, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "number_of_records = len(labels)\n",
    "shuffle = np.arange(number_of_records)\n",
    "np.random.shuffle(shuffle)\n",
    "test_fraction = 0.9\n",
    "\n",
    "#making a train / test split\n",
    "train_split, test_split = shuffle[:int(number_of_records*test_fraction)], shuffle[int(number_of_records*test_fraction):]\n",
    "trainX, trainY = word_vectors[train_split,:], labels.values[train_split,:]\n",
    "testX, testY = word_vectors[test_split,:], labels.values[test_split]\n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)\n",
    "type(testX[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a quick batch system\n",
    "def get_next_batch(batch_size,i):\n",
    "    return trainX[(i*batch_size):((i+1)*batch_size)].astype('float32'),trainY[(i*batch_size):((i+1)*batch_size)].astype('float32')\n",
    "\n",
    "# Testing\n",
    "batch_x, batch_y = get_next_batch(100,3)\n",
    "batch_x[0:5]\n",
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Hyper Parameters \n",
    "learning_rate = 0.001 \n",
    "training_epochs = 8\n",
    "batch_size = 100\n",
    "display_step = 2  # for how often to print out our results\n",
    "model_path = \"./talk_save/model_sentiment.ckpt\"\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 10000 # we now have 10k vectors of our words\n",
    "n_hidden_1 = 384 # 1st layer number of neurons\n",
    "n_hidden_2 = 100 # 2nd layer number of neurons\n",
    "n_classes = 2 # 2 classes for predicting positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The graph\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "#!rm -rf log_simple_graph\n",
    "\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input],name='X_Input')\n",
    "y = tf.placeholder(\"float\", [None, n_classes],name='Y_Input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    \n",
    "    # Hidden layer 01 with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])  # adding (x + w1 + bias1)\n",
    "    layer_1 = tf.nn.relu(layer_1, name='Layer1_Relu') #activation\n",
    "    \n",
    "    # Hidden layer 02 with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2, name='Layer2_Relu')\n",
    "    \n",
    "    # Logits layer with linear activation\n",
    "    logits_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    #logits_layer = tf.nn.softmax(logits_layer)\n",
    "    return logits_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_input, n_hidden_1],stddev = 0.1)),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2],stddev = 0.1)),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_2, n_classes],stddev = 0.1))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.ones([n_hidden_1])/10),\n",
    "    'b2': tf.Variable(tf.ones([n_hidden_2])/10),\n",
    "    'out': tf.Variable(tf.ones([n_classes])/10)\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "\n",
    "# this is were we compute error against the correct results\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))*100\n",
    "\n",
    "# optimizer made to change weights and biases to optimize cost\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss) \n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Saver' op to save and restore all the variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_y = tf.summary.scalar('output', y)\n",
    "file_writer = tf.summary.FileWriter('log_simple_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Loss = nan\n",
      "Epoch: 0003 Loss = nan\n",
      "Epoch: 0005 Loss = nan\n",
      "Epoch: 0007 Loss = nan\n",
      "Training Finished!\n",
      "Model saved in file: ./talk_save/model_sentiment.ckpt\n",
      "CPU times: user 9min 31s, sys: 29.7 s, total: 10min 1s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(len(reviews)/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = get_next_batch(100,i)\n",
    "            #print(batch_x[0])\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, loss], feed_dict={x: batch_x, y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"Loss =\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    print (\"Training Finished!\")\n",
    "    \n",
    "    # Save model weights to disk\n",
    "    save_path = saver.save(sess, model_path)\n",
    "    print (\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored from file: ./talk_save/model_sentiment.ckpt\n",
      "Accuracy: 0.8812\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Restore model weights from previously saved model\n",
    "    load_path = saver.restore(sess, model_path)\n",
    "    print (\"Model restored from file: %s\" % save_path)\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print (\"Accuracy:\", accuracy.eval({x: testX, y: testY}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_text(text_string):\n",
    "    textVec= text_to_vector(text_string)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Restore model weights from previously saved model\n",
    "        load_path = saver.restore(sess, model_path)\n",
    "        # Predict model 1 image batch size = 1\n",
    "        vector = sess.run(pred, feed_dict={x: [textVec]})\n",
    "        #print(vector[0])\n",
    "        pred_label = sess.run(tf.argmax(vector[0],0))\n",
    "        #print the label\n",
    "        if pred_label == 1: \n",
    "            print('Positive')\n",
    "        else:\n",
    "            print('Negative')\n",
    "        \n",
    "predict_text(\"lion is a great movie to watch this year\")\n",
    "\n",
    "predict_text(\"this was worst experience in a long\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    \n",
    "    with tf.name_scope('hidden_01') as scope:\n",
    "        # Hidden layer 01 with RELU activation\n",
    "        layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'],name='Layer1_matmul')  # adding (x + w1 + bias1)\n",
    "        layer_1 = tf.nn.relu(layer_1, name='Layer1_Relu') #activation\n",
    "        \n",
    "    with tf.name_scope('hidden_02') as scope:\n",
    "        # Hidden layer 02 with RELU activation\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'],name='Layer2_add')\n",
    "        layer_2 = tf.nn.relu(layer_2, name='Layer2_Relu')\n",
    "    with tf.name_scope('output_layer') as scope:\n",
    "        # Logits layer with linear activation\n",
    "        logits_layer = tf.matmul(layer_2, weights['out'],name='logits') + biases['out']\n",
    "        #logits_layer = tf.nn.softmax(logits_layer)\n",
    "    return logits_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "#with tf.name_scope('weights') as scope:\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1]),name='h1_weights'),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]),name='h2_weights'),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]),name='output_weights')\n",
    "}\n",
    "#with tf.name_scope('biases') as scope:\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1]),name='b1_bias'),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2]),name='b2_bias'),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]),name='out_bias')\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weights & biases\n",
    "with tf.name_scope('weights') as scope:\n",
    "    \n",
    "    h2w = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]),name='h2_weights')\n",
    "    ow = tf.Variable(tf.random_normal([n_hidden_2, n_classes]),name='output_weights')\n",
    "    #tensorboard histograms\n",
    "    tf.summary.histograms('weights_h1',h1w)\n",
    "    tf.summary.histograms('bias_h1',h1b)\n",
    "    \n",
    "with tf.name_scope('biases') as scope:\n",
    "    h1b = tf.Variable(tf.random_normal([n_hidden_1]),name='b1_bias')\n",
    "    h2b = tf.Variable(tf.random_normal([n_hidden_2]),name='b2_bias')\n",
    "    ob = tf.Variable(tf.random_normal([n_classes]),name='out_bias')\n",
    "    \n",
    "    \n",
    "weights = {h1w,h2w,ow}\n",
    "biases = {h1b,h2b,ob}\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    \n",
    "    with tf.name_scope('hidden_01') as scope:\n",
    "        # Hidden layer 01 with RELU activation\n",
    "        layer_1 = tf.add(tf.matmul(x, h1w), h1b,name='Layer1_matmul')  # adding (x + w1 + bias1)\n",
    "        layer_1 = tf.nn.relu(layer_1, name='Layer1_Relu') #activation\n",
    "        \n",
    "    with tf.name_scope('hidden_02') as scope:\n",
    "        # Hidden layer 02 with RELU activation\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, h2w), h2b,name='Layer2_add')\n",
    "        layer_2 = tf.nn.relu(layer_2, name='Layer2_Relu')\n",
    "\n",
    "    \n",
    "    with tf.name_scope('output_layer') as scope:\n",
    "        # Logits layer with linear activation\n",
    "        logits_layer = tf.matmul(layer_2, ow,name='logits') + ob\n",
    "        #logits_layer = tf.nn.softmax(logits_layer)\n",
    "\n",
    "    return logits_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weights & biases\n",
    "with tf.name_scope('hid_01') as scope:\n",
    "    h1w = tf.Variable(tf.random_normal([n_input, n_hidden_1]),name='h1_weights')\n",
    "    h1b = tf.Variable(tf.random_normal([n_hidden_1]),name='b1_bias')\n",
    "    #tensorboard histograms\n",
    "    tf.summary.histogram('weights_h1',h1w)\n",
    "    tf.summary.histogram('bias_h1',h1b)\n",
    "    \n",
    "    \n",
    "with tf.name_scope('hid_02') as scope:\n",
    "    h2w = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]),name='h2_weights')\n",
    "    h2b = tf.Variable(tf.random_normal([n_hidden_2]),name='b2_bias')\n",
    "    #tensorboard histograms\n",
    "    tf.summary.histogram('weights_h2',h2w)\n",
    "    tf.summary.histogram('bias_h2',h2b)\n",
    "    \n",
    "with tf.name_scope('out_layer') as scope:\n",
    "    ow = tf.Variable(tf.random_normal([n_hidden_2, n_classes]),name='output_weights')\n",
    "    ob = tf.Variable(tf.random_normal([n_classes]),name='out_bias')\n",
    "    \n",
    "weights = {h1w,h2w,ow}\n",
    "biases = {h1b,h2b,ob}\n",
    "# Construct model\n",
    "#pred = multilayer_perceptron(x, weights, biases)\n",
    "pred = multilayer_perceptron(x)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
