{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for NMT Model\n",
    "\n",
    "This example was taken from the wonderful Cutting Edge Deep Learning for Coders course as taught by Jeremy Howard http://course.fast.ai/part2.html The course is now live and I encourage you to check it out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "#import sutils; importlib.reload(sutils)\n",
    "from sutils import *\n",
    "\n",
    "import keras\n",
    "import gensim\n",
    "import re\n",
    "import pickle\n",
    "import collections\n",
    "import keras.backend as K\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras import initializers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, ReduceLROnPlateau, LearningRateScheduler, EarlyStopping, TensorBoard\n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "\n",
    "from recurrentshop import *\n",
    "import seq2seq\n",
    "from seq2seq.models import AttentionSeq2Seq,SimpleSeq2Seq, Seq2Seq\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we will use **gensim** and **word2vec** to get our embeddings for English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_gpu_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path='/home/samwit/ai_data_local/neural_translation/'\n",
    "dpath = '/home/samwit/ai_data_local/neural_translation/translate/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Corpus\n",
    "\n",
    "we will make a limited corpus of English Questions and their partners in French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname=path+'giga-fren.release2.fixed'\n",
    "en_fname = fname+'.en'\n",
    "fr_fname = fname+'.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this creates the Regex for filtering just for questions\n",
    "re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_fq = re.compile('^([^?.!]+\\?)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this runs our regex search on the full corpus and filters it down\n",
    "lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
    "         for eq, fq in zip(open(en_fname), open(fr_fname)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to put them all in a list so that we can easily access them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52331"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = [(e.group(), f.group()) for e,f in lines if e and f]\n",
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What is the major aboriginal group on Vancouver Island?',\n",
       "  'Quel est le groupe autochtone principal sur l’île de Vancouver?'),\n",
       " ('What are the advantages and disadvantages of using an online atlas versus a paper atlas?',\n",
       "  'Quels sont les avantages et les désavantages d’utiliser un atlas en ligne comparativement à un atlas en copie papier?'),\n",
       " ('What types of land cover are associated with the colours below?',\n",
       "  'À quel type de couverture des terres associez-vous les couleurs ci-dessous?'),\n",
       " ('What is the population of Canada?', 'Quelle est la population du Canada ?'),\n",
       " ('Which province is the most populated?',\n",
       "  'Quelle est la province la plus peuplée ?')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[5:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets save this so we can come back to it in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump(questions, dpath+'questions.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "loading and unwrapping the raw English/French questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions = load(dpath+'questions.pkl')\n",
    "en_qs, fr_qs = zip(*questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to split the questions into tokens so that we can make sequences for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_mult_space = re.compile(r\"  *\")\n",
    "re_mw_punc = re.compile(r\"(\\w[’'])(\\w)\")\n",
    "re_punc = re.compile(\"([\\\"().,;:/_?!—])\")\n",
    "re_apos = re.compile(r\"(\\w)'s\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_toks(sent):\n",
    "    sent = re_apos.sub(r\"\\1 's\", sent)\n",
    "    sent = re_mw_punc.sub(r\"\\1 \\2\", sent)\n",
    "    sent = re_punc.sub(r\" \\1 \", sent).replace('-', ' ')\n",
    "    sent = re_mult_space.sub(' ', sent)\n",
    "    return sent.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['qu’', 'est', 'ce', 'que', 'la', 'lumière', '?'],\n",
       " ['où', 'sommes', 'nous', '?'],\n",
       " [\"d'\", 'où', 'venons', 'nous', '?'],\n",
       " ['que', 'ferions', 'nous', 'sans', 'elle', '?']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_qtoks = list(map(simple_toks, fr_qs)); fr_qtoks[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['what', 'is', 'light', '?'],\n",
       " ['who', 'are', 'we', '?'],\n",
       " ['where', 'did', 'we', 'come', 'from', '?'],\n",
       " ['what', 'would', 'we', 'do', 'without', 'it', '?']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_qtoks = list(map(simple_toks, en_qs)); en_qtoks[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to convert tokens to ids so that we can creat lookup tables   \n",
    "\n",
    "we also insert the \"PAD\" token in here\n",
    "\n",
    "this function returns\n",
    "ids - for words\n",
    "vocab -  \n",
    "w2id - is for looking up the \n",
    "voc_cnt - the vocab count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toks2ids(sents):\n",
    "    voc_cnt = collections.Counter(t for sent in sents for t in sent)\n",
    "    vocab = sorted(voc_cnt, key=voc_cnt.get, reverse=True)\n",
    "    vocab.insert(0, \"<PAD>\")\n",
    "    w2id = {w:i for i,w in enumerate(vocab)}\n",
    "    ids = [[w2id[t] for t in sent] for sent in sents]\n",
    "    return ids, vocab, w2id, voc_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19548, 26708)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_ids, fr_vocab, fr_w2id, fr_counts = toks2ids(fr_qtoks)\n",
    "en_ids, en_vocab, en_w2id, en_counts = toks2ids(en_qtoks)\n",
    "len(en_vocab), len(fr_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentences converted to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 9, 41, 1]\n",
      "['who', 'are', 'we', '?']\n"
     ]
    }
   ],
   "source": [
    "print(en_ids[1])\n",
    "print(en_qtoks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The look up tables / dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'who'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_w2id['who']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "\n",
    "here we are going to make look up tables for words to embeddings\n",
    "\n",
    "The GloVE embeddings used here are 400k words with 100 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_glove(loc):\n",
    "    return (load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb'), encoding='latin1'),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb'), encoding='latin1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_vecs, en_wv_word, en_wv_idx = load_glove('/home/samwit/ai_data_local/embeddings/glove/6B.100d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_w2v = {w: en_vecs[en_wv_idx[w]] for w in en_wv_word}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_en_vec, dim_en_vec = en_vecs.shape\n",
    "dim_fr_vec = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_en_vec\n",
    "n_en_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fr_wik = pickle.load(open('/home/samwit/ai_data_local/embeddings/french/polyglot-fr.pkl', 'rb'), \n",
    "                     encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The French embeddings were trained by Jean-Philippe Fauconnier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Word vectors: http://fauconnier.github.io/index.html#wordembeddingmodels\n",
    "- frWac: http://wacky.sslmit.unibo.it/doku.php?id=corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_path='/home/samwit/ai_data_local/embeddings/french/frWac_non_lem_no_postag_no_phrase_200_skip_cut100.bin'\n",
    "\n",
    "fr_model = gensim.models.KeyedVectors.load_word2vec_format(w2v_path, binary=True)\n",
    "fr_voc = fr_model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_emb(w2v, targ_vocab, dim_vec):\n",
    "    vocab_size = len(targ_vocab)\n",
    "    emb = np.zeros((vocab_size, dim_vec))\n",
    "\n",
    "    for i, word in enumerate(targ_vocab):\n",
    "        try:\n",
    "            emb[i] = w2v[word]\n",
    "        except KeyError:\n",
    "            # If we can't find the word, randomly initialize\n",
    "            emb[i] = normal(scale=0.6, size=(dim_vec,))\n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19548, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_embs = create_emb(en_w2v, en_vocab, dim_en_vec); en_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26708, 200)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_embs = create_emb(fr_model, fr_vocab, dim_fr_vec); fr_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_lengths = collections.Counter(len(s) for s in en_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras pad_sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_padded = pad_sequences(en_ids, maxlen, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fr_padded = pad_sequences(fr_ids, maxlen, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52331, 30), (52331, 30), (19548, 100))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_padded.shape, fr_padded.shape, en_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = int(len(en_ids)*0.9)\n",
    "idxs = np.random.permutation(len(en_ids))\n",
    "fr_train, fr_test = fr_padded[idxs][:n], fr_padded[idxs][n:]\n",
    "en_train, en_test = en_padded[idxs][:n], en_padded[idxs][n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   18,    52,  3697, 12345,    10,     2,  3823,  2045,   765,\n",
       "           2,  1901,    31,     2, 16686,     1,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# needed to save  \n",
    "look_ups = {'en_w2id':en_w2id,'fr_vocab':fr_vocab,'en_vocab':en_vocab, 'en_embs':en_embs,'fr_embs':fr_embs}\n",
    "dump(look_ups, dpath+'look_ups.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data={'fr_train':fr_train,'en_train':en_train,'fr_test':fr_test,'en_test':en_test,}\n",
    "dump(data, dpath+'nmt_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {
    "0266aff821744178bf198185fbbd5cf1": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "0e7384b4c75d437bb1fe8a9693658cb9": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "0e8fac4707f042aa903fb0d99a10db34": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "10ab8aa7a96e46bfb356fb50841de35b": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "1a324d73121342268fb3bdab4e0ddc85": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "26e3d517d1ad4ef4bb1a8667f380e84f": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "38965a9c75124e138d24ea4b3f1aaf51": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "39d8f35bd1bf412db5e388165d2e681d": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "4e1524bdbc094d2aaf762062679cad12": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "54e930da987a4d388a10f95ef9d0d29f": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "60a3f36c191a48a68b0b5d7043d7ee2c": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "7beff7f32b174d6a84b40a07a84298a6": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "852f44c6c8ac41a8bf8b52261d56025a": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "85514cbcb43b4a53abdd0fb2d1fe9edc": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "8a27aec095a34b64b559873253a8ceb6": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "8a63b516aeb9441abdff56dd973c2dcb": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "9921ef0dc7714826b9a4dd210002cadd": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "a1e4974f09e7444d9e724242cd48193c": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "a53dd4f9998848ca9ac1b303a729dc9a": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "abdda4152496465d8e592203c90dc443": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "c48ca8a0c97a4eb1bdd6ace69e114ffd": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "ce4ee282c7f643649dee064b54a53748": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "def4852d68a14e1ea7576b27b67b6f17": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "e04977fa4cf64be59e9e55bcb898f3d7": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "e08e2127395a4003a14814472a0af7f4": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "ec407f689bac48bab95ac233b45a8976": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "eca29ad2f8734cafab240977b6d5b4f1": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "edc814ed0e054bafab4417b5fef593e1": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "eeb590879c164660ae58bf4f4bd18d25": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "fb22a8a5bcda4a97a91076cf88190fd1": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "ff9739632a7640d8984e8803859c050b": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
